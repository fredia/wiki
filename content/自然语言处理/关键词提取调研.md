---
title: "关键词提取调研"
layout: page
date: 2019-11-15 14:00
---

[TOC]

# 1 unsupervised method
## 1.1 statistics-based
## 1.2 graph-based
### 1.2.1 概览
#### textRank

第一个基于图的关键词提取方法。
- 分词，标注POS标签
- 句法过滤：只留下形容词和名次
- 将过滤后的词加入图，图的每个节点的初始分数是1，如果两个词共同出现在大小为M的窗口中，则在两个词间加一条边
- 计算节点的分数：
$$
S\left(V_{i}\right)=(1-\lambda)+\lambda * \sum_{j \in N\left(V_{i}\right)} \frac{1}{N\left(V_{j}\right)} S\left(V_{j}\right)
$$
其中$N(V_{i})$是$V_i$的邻接节点，一旦算法收敛，节点按降序排序

- 取top T作为关键词

#### singleRank

singleRank是基于TextRank的改进,进一步考虑了边的权重。边的权重等于两个词(短语)中的共现词的数量。
$$
W S\left(V_{i}\right)=(1-\lambda)+\lambda * \sum_{j \in N\left(V_{i}\right)} \frac{\#_{c} i j}{\sum v_{k} \in N\left(V_{j}\right)\#_{c}  j k} W S\left(V_{j}\right)
$$
其中$\#_c i j $是短语i和短语j间共同出现的词的数量
#### RAKE

- 输入参数：停用词，单词分割符，句子分割符，从句子中提取出候选词(短语)
- 创建共现词的图，节点的分数为：词频或者为节点的度与频率的比
- RAKE能够通过检测在同一文档中至少两次相邻的词对来识别包含内部停止词的关键短语
- 取top T作为关键词
#### SGRank

- 从输入文本找那个提取所有可能的n-gram，消除标点和 名次，形容词和动词之外的词，进一步考虑term的频率
- 基于修改后的TFIdf(和KP-Miner相似)对候选n-gram进行排序
- 排名靠前的候选词将根据额外的启发式统计方法(例如第一次出现的位置和term长度)重新排序
- 第三阶段的排名被合并到基于图的算法
#### PositionRank

PositionRank是一种基于图的无监督方法，考虑到单词共现及其在文本中的相应位置，尝试捕获频繁短语。具体来说，将一个单词放入一个有偏加权的PageRank中。最后，对关键短语进行评分和排序。

### 1.2.2 Incorporating Information from Similar Documents/Citation Networks

前面讨论的基于图的方法假设文档彼此独立。因此，在关键词提取过程中只有目标文档中包含的信息被使用，即短语的TfIdf、位置等。然而，相关文档相互影响，这些信息有助于提取关键短语。

#### ExpandRank
expandRank是对singleRank的扩展，试图解决仅依靠单篇文章结构的共现窗口产生的噪声问题。对每一篇文章都选取一定数目的邻居文章作为补充信息，作为对单篇文章统计的补充。

- 邻居文档的构建：基于相似文章搜索技术

- 关键字抽取,包括：

    - 邻居级词语抽取，对邻居文档基于图算法（textrank）构建潜在关键词网络

    - 文档级关键词抽取，基于打分函数抽取关键词

    $$
    e\left(v_{i}, v_{j}\right)=\sum_{d_{k} \in D} \operatorname{sim}\left(d_{0}, d_{k}\right) \times \text { freq }_{d_{k}}\left(v_{i}, v_{j}\right)
    $$

对比传统和方法的优势：

一定程度上解决解决了对统计方法提取关键字的依赖，扩展了只依靠单篇文章结构的textrank，提高了准确率。

缺点：

由于邻居文档选取的不确定性会产生语义漂移问题。

#### CiteTextRank

整合了引用网络的关键词信息。
$$
e_{i j}=\sum_{t \in T C} \sum_{c \in C_{t}} \lambda_{t} \cdot \operatorname{sim}(c, d) \cdot \#_{c}\left(v_{i}, v_{j}\right)
$$

TC是$d(global,citing,cited)$上下文中可用的types，$sim(c,d)$是d中人格上下文c和d的TFidf cos相似度。


### 1.2.3 Topic-based Method

#### clustering-based Methods
##### topicRank

 - 提取出候选词
 - 使用 hierarchical agglomerative clustering(凝聚层次聚类)将候选词句读不同的topic中。
 - 建topic图，边的权重为：根据短语在文本中的偏移位置进行加权。
 - 使用textRan计算topic排名，从最重要的topic中，每个选出一个候选词作为关键词
##### multipartiteRank

引入了中间步骤，在中间步骤中调整边缘权重以捕获位置信息，从而使文档中较早出现的关键词候选出现偏差。

#### LDA-based
##### Topical PageRank
使用LDA来获得每个单词w主题分布$pr(z|w)$，对每一个文档d，基于形容词和名词间的共现来构建图。TPR的思想是对每一个主题跑一个基本的PageRank算法，对每个topic，节点的分数为：
$$
S_{z}\left(w_{i}\right)=\lambda \sum_{j: w_{j} \rightarrow w_{i}} \frac{e\left(w_{j}, w_{i}\right)}{O\left(w_{j}\right)} S_{z}\left(w_{j}\right)+(1-\lambda) p_{z}\left(w_{i}\right)
$$
其中$p_{z}{(w_i)}$等于$pr(z|w)$,代表给定w，主题z的概率。$\lambda$是阻尼系数，$O(w_j)$是节点$w_j$的出度

$$
S_{z}(p)=\sum_{w_{i} \in p} S_{z}\left(w_{i}\right)
$$


$$
S(p)=\sum_{1}^{K} S_{z}(p) \times \operatorname{pr}(z | d)
$$
##### Single Topical PageRank
避免TRP对于每个主题计算PageRank的开销，对所有的文档只运行一次PageRank。

引入$W(w_i)$来代替$p_z (w_i)$
$$
S\left(w_{i}\right)=\lambda \sum_{j: w_{j} \rightarrow w_{i}} \frac{e\left(w_{j}, w_{i}\right)}{O\left(w_{j}\right)} S\left(w_{j}\right)+(1-\lambda) \frac{W\left(w_{i}\right)}{\sum_{w \in V} W(w)}
$$

##### Salience Rank
和Single TPR非常相似，只跑一次PageRank。$S_a (w)$是主题特殊性和语料特殊性(至少可以计算出特殊语料中的单词频率)的线性组合。直观的说，主题特殊性衡量了一个单词出现在多少不同的主题中(出现该单词的主题越少，该单词的主题特殊性越高)。
$$
S\left(w_{i}\right)=\lambda \sum_{j: w_{j} \rightarrow w_{i}} \frac{e\left(w_{j}, w_{i}\right)}{O\left(w_{j}\right)} S\left(w_{j}\right)+(1-\lambda) \times S_{\alpha}\left(w_{i}\right)
$$
### 1.2.4 Graph-based method with Semantics

#### 来自KG的语义信息
&emsp;&emsp;基于主题的方法存在的主要问题是主题过于笼统和模糊。基于共现的方法会遭受信息丢失，也就是说，如果在文档中，尽管它们在语义上是相关的，但在相应的词图中却没有连接它们的边，而基于统计的方法则存在信息过载，即词的真实意义
在文档中可能会被大量用于统计计算的外部文本淹没信息。为了解决这些问题，并结合语义进行关键词提取，Shi等人（2017）提议一种使用知识图的关键词提取系统。首先，选择名词和命名实体（keyterms）并采用聚类的方法，根据语义相似度进行分组。然后，每个集群的关键字链接到DBpedia实体。对于每个簇，通过提取h-hop关键字来检测关键字之间的关系，来自知识图的图，即DBpedia的子图，它包含集群中两个不同节点之间长度不超过h的所有路径。然后，所有提取的簇的keyterm图被集成到一个graph，并在上面应用个性化PageRank（Haveliwala，2002）得到每个关键词的排名得分。这个候选短语的最终排名方案使用PPR分数，该分数是关键字的PPR分数之和以及短语出现的频率和第一次出现的位置。

##### wikiRank
一种无监督的自动关键词提取方法把语义和文本联系起来。
- 使用TAGME，用于topic/concept annotation，检测有意义的短语并将它们和Wikipedia中的页面关联。
- 提取一个或多个名词后跟着0个或多个形容词的短语。
- 根据concept和短语的并集 建图
- 如果一个候选短语包括一个concept，会在二者之间加一条边
- 一个concept的权重等于该concept在所有文本中的频率,即
$$
S(c)=\sum_{i=0}^{\operatorname{deg}(c)} \frac{w_{c}}{2^{i}}
$$


#### 来自预训练的语义信息

尽管利用知识图/库的语义的方法已经显示出它们的改进，但是关键词提取过程需要更多的背景知识而不仅仅是语义关系信息。因此，Wang等人（2014）提出了一个基于图的排序模型，该模型考虑了来自分布式的语义信息作为背景知识的单词表示法。

## 1.3 embedding-based Methods
## 1.4 Language Model-based Methods
